name: Help Center changed files scraper

on:
  pull_request:
    branches:
      - main
    types: [closed]

jobs:
  scrape-files:
    runs-on: ubuntu-latest
    name: Scraper running
    steps:
      - uses: actions/checkout@v4
      - name: Get changed markdown files
        id: changed-files
        uses: tj-actions/changed-files@v43
        with:
          include_all_old_new_renamed_files: "true"
          files: |
            **.md
            **.mdx
          separator: ","
      - name: Save file lists
        run: |
          echo "${{ steps.changed-files.outputs.added_files }}" > added_files.txt
          echo "${{ steps.changed-files.outputs.modified_files }}" > modified_files.txt
          echo "${{ steps.changed-files.outputs.deleted_files }}" > deleted_files.txt
          echo "${{ steps.changed-files.outputs.all_old_new_renamed_files }}" > renamed_files.txt
      - name: Printing
        run: |
          echo "All files count: $(wc -l < added_files.txt)"
          echo "Added files count: $(wc -l < added_files.txt)"
          echo "Deleted files count: $(wc -l < deleted_files.txt)"
          echo "Modified files count: $(wc -l < modified_files.txt)"
          echo "Renamed files count: $(wc -l < renamed_files.txt)"
          
          echo "First 100 files in each category:"
          echo "Added:"
          head -n 100 added_files.txt
          echo "Modified:"
          head -n 100 modified_files.txt
          echo "Deleted:"
          head -n 100 deleted_files.txt
          echo "Renamed:"
          head -n 100 renamed_files.txt
      - name: Process files
        id: process-files
        run: |
          # Function to process files in chunks
          process_files() {
            local file=$1
            local chunk_size=$2
            local type=$3
            local total=$(wc -l < "$file")
            local i=0

            while [ $i -lt $total ]; do
              local end=$((i + chunk_size))
              [ $end -gt $total ] && end=$total
              
              # Get the chunk of files
              local chunk=$(sed -n "$((i+1)),${end}p" "$file" | tr '\n' ',' | sed 's/,$//')
              echo "Processing $type files: $((i+1)) to $end of $total"
              
              # Run the chunk processor workflow
              if ! gh workflow run docsearch-scraper-chunk.yml -f type="$type" -f files="$chunk"; then
                echo "Error processing chunk, reducing size and retrying..."
                chunk_size=$((chunk_size / 2))
                if [ $chunk_size -lt 5 ]; then
                  echo "Chunk size too small, aborting"
                  return 1
                fi
                continue
              fi
              
              i=$end
            done
            return 0
          }

          # Process each type of files separately with a small initial chunk size
          CHUNK_SIZE=1000
          
          if [ -s added_files.txt ]; then
            echo "Processing added files..."
            process_files added_files.txt $CHUNK_SIZE "added" || exit 1
          fi
          
          if [ -s modified_files.txt ]; then
            echo "Processing modified files..."
            process_files modified_files.txt $CHUNK_SIZE "updated" || exit 1
          fi
          
          if [ -s deleted_files.txt ]; then
            echo "Processing deleted files..."
            process_files deleted_files.txt $CHUNK_SIZE "removed" || exit 1
          fi
          
          if [ -s renamed_files.txt ]; then
            echo "Processing renamed files..."
            process_files renamed_files.txt $CHUNK_SIZE "renamed" || exit 1
          fi

          # Clean up
          rm -f added_files.txt modified_files.txt deleted_files.txt renamed_files.txt
